// VISOS/action/verbalizers/lipSync/lipSyncService.js
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import { interpret } from 'xstate';
import { lipSyncMachine } from './lipSyncMachine';          // Web-Speech only
import { neutralVisemes } from '../../../cognition/facs/facsService';
import { createAnimationService } from '../../visualizers/animation/animationService';

/**
 * initLipSyncService({ engine:'webSpeech' | 'sapi', rate })
 *   â€¢ Web-Speech: uses a rolling visemeSnippet updated in real time.
 *   â€¢ SAPI:  receives the *entire* viseme array once, converts it to a
 *            visemeSnippet, and lets AnimationService play it.
 */
export function initLipSyncService({ engine = 'webSpeech', rate = 1 } = {}) {

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  //  WEB-SPEECH BRANCH  (unchanged)
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  if (engine === 'webSpeech') {
    const animSvc       = createAnimationService();   // singleton
    const SN_NAME       = 'webSpeechLive';
    const HOLD_SEC      = 0.14;                       // 140 ms hold
    const curves        = {};                         // { visId: [ {time,int}, â€¦ ] }
    let   baseTimeSec   = 0;
    let   snippetLoaded = false;

    function ensureSnippetLoaded() {
      if (snippetLoaded) return;
      animSvc.loadVisemeSnippet({
        name: SN_NAME,
        curves,
        isPlaying: true,
        loop: false,
        maxTime: 0
      }, -100);
      snippetLoaded = true;
    }

    function addKeyFrames(id, tSec) {
      curves[id].push({ time: tStart, intensity: onsetIntensity });
        const newMax = tSec + HOLD_SEC + 0.1;
        animSvc.setSnippetMaxTime(SN_NAME, newMax);
        animSvc.setAUCurve(SN_NAME, id, curves[id]);   // live update
   }

    return {
      /* Called per VISEME_START from Web-Speech TTS */
      handleViseme(id /* 0-21 */, durMs = 120) {
        const nowSec = performance.now() / 1000;
        if (baseTimeSec === 0) baseTimeSec = nowSec;
        const t = nowSec - baseTimeSec;

        ensureSnippetLoaded();
        addKeyFrames(id, t);
        animSvc.flush();        // immediate pose
      },

      stop() {
        neutralVisemes();
        animSvc.removeAnimation(SN_NAME);
        snippetLoaded = false;
        baseTimeSec   = 0;
        Object.keys(curves).forEach(k => delete curves[k]);
      },

      dispose() {
        this.stop();
        animSvc.release?.();
      }
    };
  }

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  //  SAPI BRANCH  (new builder)
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const animSvc    = createAnimationService();   // singleton
  let   currentClip = null;                      // active snippet name

  /* Build ONE animation snippet from raw SAPI viseme array.
   *   â€¢ visemeSnippet : 21 curves (IDs 0â€‘20), each idle when not active.
   */
  /* =========================================================================
   * buildVisemeSnippet â”€â”€ Build ONE visemeSnippet from a raw SAPI viseme array.
   * Every viseme curve:
   *   â€¢ Starts at 0 % at t = 0
   *   â€¢ Jumps to <onsetIntensity>% at its onset time
   *   â€¢ Holds that value for 90 % of the phoneme duration
   *   â€¢ Releases to 0 % at the end of the phoneme
   * The snippetPlaybackRate is set to the TTS rate so the timeline remains
   * correct when the engine speaks faster / slower than 1Ã—.
   * ========================================================================= */
  function buildVisemeSnippet(arr, onsetIntensity = 90, speechRate = 1) {
    const curves = {};
    for (let i = 0; i <= 20; i++) curves[i] = [{ time: 0, intensity: 0 }];

    // SAPI offsets & durations are already in milliseconds âžž seconds helper
    const toSec = (ms) => ms / 1000;

    let maxTime = 0;
    arr.forEach((v, idx) => {
      if (!v) return;
      const id = v.number;
      if (typeof id !== 'number' || id < 0 || id > 20) return;

      const onsetMs = v.offset ?? v.audioPosition ?? 0;
      const durMs =
        v.duration ??
        ((arr[idx + 1]?.offset ?? arr[idx + 1]?.audioPosition ?? (onsetMs + 140)) -
          onsetMs);

      const tStart = +toSec(onsetMs).toFixed(3);
      const hold   = durMs * 0.9;                      // 90 % hold
      const tEnd   = +(tStart + toSec(hold)).toFixed(3);

      curves[id].push(
        { time: tStart, intensity: onsetIntensity },
        { time: tEnd,   intensity: 0 }
      );

      maxTime = Math.max(maxTime, tEnd + 0.1);
    });

    // Sort each curve and ensure a closing zero at maxTime
    Object.values(curves).forEach(frames => {
      frames.sort((a, b) => a.time - b.time);
      const last = frames[frames.length - 1];
      if (last.time < maxTime || last.intensity !== 0) {
        frames.push({ time: +maxTime.toFixed(3), intensity: 0 });
      }
    });

    return {
      name:                `sapi_vis_${Date.now()}`,
      curves,
      isPlaying:           true,
      loop:                false,
      maxTime,
      snippetPlaybackRate: speechRate,
      snippetIntensityScale: 1
    };
  }

  return {
    /**
     * Call *once per utterance* when SAPI gives you the full viseme array.
     * visemeArr = [{ number, offset, duration }, â€¦]
     */
    handleSapiVisemes(visemeArr = []) {
      if (!Array.isArray(visemeArr) || visemeArr.length === 0) return;

      const snippet = buildVisemeSnippet(visemeArr, 90, rate);

      /* ðŸ”µ  DEBUG: log the full JSON weâ€™re about to play */
      console.log('SAPIâ€‘generated viseme snippet â¤µï¸Ž');
      console.log(JSON.stringify(snippet, null, 2));

      if (currentClip) animSvc.removeAnimation(currentClip);
      animSvc.loadVisemeSnippet(snippet, -100);   // flag â†’ visemeSnippet
      currentClip = snippet.name;

      animSvc.flush();  // show first keyâ€‘frame immediately
    },

    /** Interrupt or dispose midâ€‘utterance. */
    stop() {
      if (currentClip) {
        animSvc.removeAnimation(currentClip);
        currentClip = null;
      }
    },

    dispose() {
      this.stop();
      animSvc.release?.();
    }
  };
}